from PIL import Image
import torchvision.transforms as transforms
from train import model, num_classes, input_size, hidden_size  # ä»train.pyæ–‡ä»¶ä¸­å¯¼å…¥è®­ç»ƒå¥½çš„æ¨¡å‹
import torch
from model import FCNN
from dataset import result_list, label_list

# å°†æ•°æ®è½¬æ¢ä¸ºPyTorchå¼ é‡
test_data = torch.cat(result_list).float()
test_labels = [float(label) if isinstance(label, str) else label for label in label_list]
test_labels = torch.tensor(test_labels)

# åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½
with torch.no_grad():
    test_outputs = model(test_data)
    _, test_predicted = torch.max(test_outputs, 1)
    test_accuracy = (test_predicted == test_labels).sum().item() / len(test_labels)
    print(f'Test Accuracy: {test_accuracy:.4f}')

# # åŠ è½½æ¨¡å‹æƒé‡
model = FCNN(input_size, hidden_size, num_classes)
model.load_state_dict(torch.load('model_weights.pth'))

# åŠ è½½åŸå§‹å›¾ç‰‡
image_path = 'datatset/é»„èŠª (10).jpg'
image = Image.open(image_path)

# å®šä¹‰å›¾åƒé¢„å¤„ç†æ“ä½œ
transform = transforms.Compose([
    transforms.Resize((input_size, input_size)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# å°†åŸå§‹å›¾ç‰‡è½¬æ¢ä¸ºPyTorchå¼ é‡
image_tensor = transform(image).unsqueeze(0)

with torch.no_grad():
    output = model(image_tensor)
    _, predicted = torch.max(output, 1)
    predicted_index = torch.argmax(predicted).item()
    if 0 <= predicted_index < len(label_list):
        predicted_class = label_list[predicted_index]
        print("é¢„æµ‹ç±»åˆ«ï¼š", predicted_class)
    else:
        print("é¢„æµ‹å‡ºé”™")
print('ğŸ˜€')
